\BOOKMARK [0][]{pdf:title.0}{Front page}{}% 1
\BOOKMARK [0][]{pdf:toc.0}{Inhaltsverzeichnis}{}% 2
\BOOKMARK [0][]{pdf:Notation.0}{Mathematische Notation}{}% 3
\BOOKMARK [0][]{chapter.1}{Einleitung}{}% 4
\BOOKMARK [1][-]{section.1.1}{Funktionsweise eines CNN}{chapter.1}% 5
\BOOKMARK [0][]{chapter.2}{Stand der Wissenschaft}{}% 6
\BOOKMARK [1][-]{subsection.2.0.1}{Suchbegriffe}{chapter.2}% 7
\BOOKMARK [2][-]{subsection.2.0.2}{verwendete Datensets}{subsection.2.0.1}% 8
\BOOKMARK [1][-]{section.2.1}{Verringerung der f\374r Berechnungen n\366tige Zeit}{chapter.2}% 9
\BOOKMARK [2][-]{subsection.2.1.1}{Berechnung mit 16 Bit Gleitkomma}{section.2.1}% 10
\BOOKMARK [2][-]{subsection.2.1.2}{Berechnung mit 16 Bit Dynamischen Festkommazahlen}{section.2.1}% 11
\BOOKMARK [0][]{chapter.3}{Beschleunigung der Berechnung des Gradientenabstiegsverfahren}{}% 12
\BOOKMARK [1][-]{section.3.1}{Accelerating CNN Training by Sparsifying Activation Gradients}{chapter.3}% 13
\BOOKMARK [1][-]{section.3.2}{Weight Normalization: A Simple Reparameterization to Accelerate Training of Deep Neural Networks}{chapter.3}% 14
\BOOKMARK [1][-]{section.3.3}{Accelerating Deep Neural Network Training with Inconsistent Stochastic Gradient Descent}{chapter.3}% 15
\BOOKMARK [1][-]{section.3.4}{Accelerated CNN Training Through Gradient Approximation}{chapter.3}% 16
\BOOKMARK [0][]{chapter.4}{Verfahren um weniger Trainingsdaten zu verwenden}{}% 17
\BOOKMARK [1][-]{section.4.1}{Stochastisches Pooling}{chapter.4}% 18
\BOOKMARK [1][-]{section.4.2}{Lernen von Struktur und St\344rke von CNNs}{chapter.4}% 19
\BOOKMARK [0][]{chapter.5}{Strukturelle Ver\344nderungen zur Beschleunigung des Trainings}{}% 20
\BOOKMARK [1][-]{section.5.1}{Pruning um Trainingszeit zu minimieren}{chapter.5}% 21
\BOOKMARK [2][-]{subsection.5.1.1}{Prune Train}{section.5.1}% 22
\BOOKMARK [1][-]{section.5.2}{Net 2 Net}{chapter.5}% 23
\BOOKMARK [1][-]{section.5.3}{Kernel rescaling}{chapter.5}% 24
\BOOKMARK [1][-]{section.5.4}{Resource Aware Layer Replacement}{chapter.5}% 25
\BOOKMARK [0][]{chapter.6}{Weitere Herangehensweisen}{}% 26
\BOOKMARK [1][-]{section.6.1}{Tree CNN}{chapter.6}% 27
\BOOKMARK [1][-]{section.6.2}{Standardization Loss}{chapter.6}% 28
\BOOKMARK [1][-]{section.6.3}{Wavelet}{chapter.6}% 29
\BOOKMARK [-1][]{part.1}{Praktischer Teil\205 Arbeitstitel}{}% 30
\BOOKMARK [0][]{chapter.7}{Einleitung}{part.1}% 31
\BOOKMARK [0][]{chapter.8}{Durchf\374hrung}{part.1}% 32
\BOOKMARK [-1][]{part.2}{Additional information}{}% 33
\BOOKMARK [0][]{chapter*.15}{Abbildungsverzeichnis}{part.2}% 34
\BOOKMARK [0][]{chapter*.16}{Algorithmenverzeichnis}{part.2}% 35
\BOOKMARK [0][]{chapter*.17}{Quellcodeverzeichnis}{part.2}% 36
\BOOKMARK [0][]{chapter*.17}{Literaturverzeichnis}{part.2}% 37
