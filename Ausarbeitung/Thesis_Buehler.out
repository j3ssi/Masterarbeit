\BOOKMARK [0][]{chapter.1}{Einleitung}{}% 1
\BOOKMARK [1][-]{section.1.1}{Motivation\040und\040Hintergrund\040dieser\040Arbeit}{chapter.1}% 2
\BOOKMARK [1][-]{section.1.2}{Aufbau\040der\040Arbeit}{chapter.1}% 3
\BOOKMARK [0][]{chapter.2}{Stand\040der\040Wissenschaft}{}% 4
\BOOKMARK [1][-]{section.2.1}{Funktionsweise\040eines\040CNN}{chapter.2}% 5
\BOOKMARK [1][-]{section.2.2}{ResNet\040\205\040eine\040neuere\040CNN-Architektur}{chapter.2}% 6
\BOOKMARK [1][-]{section.2.3}{Vorgehen\040zur\040Suche\040nachdem\040Stand\040der\040Wissenschaft}{chapter.2}% 7
\BOOKMARK [1][-]{section.2.4}{Beschneidung\040des\040Netzes\040zur\040Beschleunigung\040des\040Training}{chapter.2}% 8
\BOOKMARK [1][-]{section.2.5}{Beschleunigung\040des\040Lernens\040durch\040Wissenstransfer}{chapter.2}% 9
\BOOKMARK [2][-]{subsection.2.5.1}{Operator\040f\374r\040breiteres\040Netz}{section.2.5}% 10
\BOOKMARK [1][-]{section.2.6}{Automatische\040Architektursuche}{chapter.2}% 11
\BOOKMARK [1][-]{section.2.7}{Schnelles\040Ressourcen\040beschr\344nktes\040Strukturlernen\040tiefer\040Netzwerke}{chapter.2}% 12
\BOOKMARK [2][-]{subsection.2.7.1}{Definition\040der\040Nebenbedingung}{section.2.7}% 13
\BOOKMARK [2][-]{subsection.2.7.2}{Regularsierer}{section.2.7}% 14
\BOOKMARK [1][-]{section.2.8}{Zeitsparende\040Nethoden}{chapter.2}% 15
\BOOKMARK [2][-]{subsection.2.8.1}{Verringerung\040der\040f\374r\040Berechnungen\040n\366tige\040Zeit}{section.2.8}% 16
\BOOKMARK [2][-]{subsection.2.8.2}{Beschleunigung\040der\040Berechnung\040des\040Gradientenabstiegsverfahren}{section.2.8}% 17
\BOOKMARK [1][-]{section.2.9}{Additive\040Methoden}{chapter.2}% 18
\BOOKMARK [2][-]{subsection.2.9.1}{Verfahren\040zum\040Verwenden\040maximaler\040Batchgr\366\337en}{section.2.9}% 19
\BOOKMARK [0][]{chapter.3}{Experimente\040\205\040Arbeitstitel}{}% 20
\BOOKMARK [1][-]{section.3.1}{Experimentales\040Setup}{chapter.3}% 21
\BOOKMARK [2][-]{subsection.3.1.1}{Hardware}{section.3.1}% 22
\BOOKMARK [2][-]{subsection.3.1.2}{Wahl\040des\040Frameworks}{section.3.1}% 23
\BOOKMARK [2][-]{subsection.3.1.3}{verwendete\040Netzarchitektur}{section.3.1}% 24
\BOOKMARK [2][-]{subsection.3.1.4}{\334berblick\040\374ber\040das\040experimentelle\040Vorgehen}{section.3.1}% 25
\BOOKMARK [1][-]{section.3.2}{Untersuchung\040von\040PruneTrain}{chapter.3}% 26
\BOOKMARK [2][-]{subsection.3.2.1}{Experimente\040zurAnpassung\040der\040Batchgr\366\337e\040beim\040Beschneiden\040des\040Netzes}{section.3.2}% 27
\BOOKMARK [2][-]{subsection.3.2.2}{Einfluss\040der\040Batchgr\366\337e\040auf\040PruneTrain}{section.3.2}% 28
\BOOKMARK [1][-]{section.3.3}{Untersuchung\040von\040Net2Net}{chapter.3}% 29
\BOOKMARK [2][-]{subsection.3.3.1}{Evaluierung\040des\040Operators\040f\374r\040ein\040breiteres\040Netz}{section.3.3}% 30
\BOOKMARK [2][-]{subsection.3.3.2}{Evaluierung\040des\040Operators\040f\374r\040ein\040tieferes\040Netz}{section.3.3}% 31
\BOOKMARK [1][-]{section.3.4}{PruneTrain\040+\040Net2Net}{chapter.3}% 32
\BOOKMARK [1][-]{section.3.5}{Untersuchung\040von\040MorphNet}{chapter.3}% 33
\BOOKMARK [1][-]{section.3.6}{Vergleich}{chapter.3}% 34
\BOOKMARK [1][-]{section.3.7}{Additive\040Verfahren}{chapter.3}% 35
\BOOKMARK [2][-]{subsection.3.7.1}{Zahlenformate}{section.3.7}% 36
\BOOKMARK [2][-]{subsection.3.7.2}{LARS}{section.3.7}% 37
\BOOKMARK [2][-]{subsection.3.7.3}{Beschleunigung\040der\040Berechnung\040des\040Gradientenabstiegverfahren}{section.3.7}% 38
\BOOKMARK [0][]{chapter.4}{Evaluation}{}% 39
\BOOKMARK [0][]{chapter.5}{Ausblick\040und\040Fazit}{}% 40
\BOOKMARK [0][]{appendix.A}{d}{}% 41
\BOOKMARK [0][]{chapter*.68}{Abbildungsverzeichnis}{}% 42
\BOOKMARK [0][]{chapter*.68}{Literaturverzeichnis}{}% 43
