\BOOKMARK [0][]{chapter.1}{Einleitung}{}% 1
\BOOKMARK [1][-]{section.1.1}{Motivation\040und\040Hintergrund\040dieser\040Arbeit}{chapter.1}% 2
\BOOKMARK [1][-]{section.1.2}{Ziel\040der\040Arbeit}{chapter.1}% 3
\BOOKMARK [1][-]{section.1.3}{Ergebnisse\040der\040Arbeit}{chapter.1}% 4
\BOOKMARK [1][-]{section.1.4}{Aufbau\040der\040Arbeit}{chapter.1}% 5
\BOOKMARK [0][]{chapter.2}{Stand\040der\040Wissenschaft}{}% 6
\BOOKMARK [1][-]{section.2.1}{Funktionsweise\040eines\040CNN}{chapter.2}% 7
\BOOKMARK [1][-]{section.2.2}{ResNet\040\205\040eine\040neuere\040CNN-Architektur}{chapter.2}% 8
\BOOKMARK [1][-]{section.2.3}{Vorgehen\040zur\040Suche\040nachdem\040Stand\040der\040Wissenschaft}{chapter.2}% 9
\BOOKMARK [1][-]{section.2.4}{Beschneidung\040des\040Netzes\040zur\040Beschleunigung\040des\040Training}{chapter.2}% 10
\BOOKMARK [1][-]{section.2.5}{Beschleunigung\040des\040Lernens\040durch\040Wissenstransfer}{chapter.2}% 11
\BOOKMARK [2][-]{subsection.2.5.1}{Operator\040f\374r\040breiteres\040Netz}{section.2.5}% 12
\BOOKMARK [1][-]{section.2.6}{Automatische\040Architektursuche}{chapter.2}% 13
\BOOKMARK [1][-]{section.2.7}{Schnelles\040Ressourcen\040beschr\344nktes\040Strukturlernen\040tiefer\040Netzwerke}{chapter.2}% 14
\BOOKMARK [2][-]{subsection.2.7.1}{Definition\040der\040Nebenbedingung}{section.2.7}% 15
\BOOKMARK [2][-]{subsection.2.7.2}{Regularsierer}{section.2.7}% 16
\BOOKMARK [1][-]{section.2.8}{Zeitsparende\040Nethoden}{chapter.2}% 17
\BOOKMARK [2][-]{subsection.2.8.1}{Verringerung\040der\040f\374r\040Berechnungen\040n\366tige\040Zeit}{section.2.8}% 18
\BOOKMARK [2][-]{subsection.2.8.2}{Beschleunigung\040der\040Berechnung\040des\040Gradientenabstiegsverfahren}{section.2.8}% 19
\BOOKMARK [1][-]{section.2.9}{Additive\040Methoden}{chapter.2}% 20
\BOOKMARK [2][-]{subsection.2.9.1}{Verfahren\040zum\040Verwenden\040maximaler\040Batchgr\366\337en}{section.2.9}% 21
\BOOKMARK [0][]{chapter.3}{Konzeptionelle\040\334bersicht\040\205\040Arbeitstitel}{}% 22
\BOOKMARK [1][-]{section.3.1}{Experimentales\040Setup}{chapter.3}% 23
\BOOKMARK [2][-]{subsection.3.1.1}{Hardware}{section.3.1}% 24
\BOOKMARK [2][-]{subsection.3.1.2}{Wahl\040des\040Frameworks}{section.3.1}% 25
\BOOKMARK [2][-]{subsection.3.1.3}{verwendete\040Netzarchitektur}{section.3.1}% 26
\BOOKMARK [2][-]{subsection.3.1.4}{Baseline\040Netz}{section.3.1}% 27
\BOOKMARK [1][-]{section.3.2}{Konzept}{chapter.3}% 28
\BOOKMARK [0][]{chapter.4}{Untersuchung\040von\040MorphNet}{}% 29
\BOOKMARK [0][]{chapter.5}{PruneTrain}{}% 30
\BOOKMARK [1][-]{section.5.1}{Untersuchung\040von\040PruneTrain}{chapter.5}% 31
\BOOKMARK [0][]{chapter.6}{Untersuchung\040der\040eigenen\040Implementierungen}{}% 32
\BOOKMARK [1][-]{section.6.1}{Experimente\040zur\040Anpassung\040der\040Batchgr\366\337e\040beim\040Beschneiden\040des\040Netzes}{chapter.6}% 33
\BOOKMARK [2][-]{subsection.6.1.1}{Einfluss\040der\040Batchgr\366\337e\040auf\040PruneTrain}{section.6.1}% 34
\BOOKMARK [1][-]{section.6.2}{Untersuchung\040von\040Net2Net}{chapter.6}% 35
\BOOKMARK [2][-]{subsection.6.2.1}{Evaluierung\040des\040Operators\040f\374r\040ein\040breiteres\040Netz}{section.6.2}% 36
\BOOKMARK [2][-]{subsection.6.2.2}{Evaluierung\040des\040Operators\040f\374r\040ein\040tieferes\040Netz}{section.6.2}% 37
\BOOKMARK [1][-]{section.6.3}{PruneTrain\040+\040Net2Net}{chapter.6}% 38
\BOOKMARK [0][]{chapter.7}{Vergleich}{}% 39
\BOOKMARK [0][]{chapter.8}{Additive\040Verfahren}{}% 40
\BOOKMARK [1][-]{subsection.8.0.1}{Zahlenformate}{chapter.8}% 41
\BOOKMARK [2][-]{subsection.8.0.2}{LARS}{subsection.8.0.1}% 42
\BOOKMARK [2][-]{subsection.8.0.3}{Beschleunigung\040der\040Berechnung\040des\040Gradientenabstiegverfahren}{subsection.8.0.1}% 43
\BOOKMARK [0][]{chapter.9}{Evaluation}{}% 44
\BOOKMARK [0][]{chapter.10}{Ausblick\040und\040Fazit}{}% 45
\BOOKMARK [0][]{appendix.A}{d}{}% 46
\BOOKMARK [0][]{chapter*.66}{Abbildungsverzeichnis}{}% 47
\BOOKMARK [0][]{chapter*.66}{Literaturverzeichnis}{}% 48
