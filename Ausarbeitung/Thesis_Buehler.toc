\babel@toc {german}{}
\contentsline {chapter}{\numberline {1}Einleitung}{1}{chapter.1}
\contentsline {section}{\numberline {1.1}Motivation und Hintergrund dieser Arbeit}{1}{section.1.1}
\contentsline {section}{\numberline {1.2}Ziel der Arbeit}{2}{section.1.2}
\contentsline {section}{\numberline {1.3}Ergebnisse der Arbeit}{2}{section.1.3}
\contentsline {section}{\numberline {1.4}Aufbau der Arbeit}{2}{section.1.4}
\contentsline {chapter}{\numberline {2}Stand der Wissenschaft}{5}{chapter.2}
\contentsline {section}{\numberline {2.1}Funktionsweise eines CNN}{5}{section.2.1}
\contentsline {section}{\numberline {2.2}ResNet -- eine neuere CNN-Architektur}{9}{section.2.2}
\contentsline {section}{\numberline {2.3}Vorgehen zur Suche nach dem Stand der Wissenschaft}{11}{section.2.3}
\contentsline {section}{\numberline {2.4}Beschneidung des Netzes zur Beschleunigung des Trainings}{13}{section.2.4}
\contentsline {section}{\numberline {2.5}Beschleunigung des Lernens durch Wissenstransfer}{17}{section.2.5}
\contentsline {subsubsection}{\nonumberline Operator f\IeC {\"u}r breiteres Netz}{17}{section*.14}
\contentsline {subsubsection}{\nonumberline Tieferes Netz}{19}{section*.17}
\contentsline {subsubsection}{\nonumberline Diskussion der Methode}{19}{section*.18}
\contentsline {section}{\numberline {2.6}Automatische Architektursuche}{19}{section.2.6}
\contentsline {section}{\numberline {2.7}Schnelles Ressourcen-beschr\IeC {\"a}nktes Strukturlernen tiefer Netzwerke}{20}{section.2.7}
\contentsline {subsection}{\numberline {2.7.1}Definition der Nebenbedingung}{22}{subsection.2.7.1}
\contentsline {subsection}{\numberline {2.7.2}Regularsierer}{23}{subsection.2.7.2}
\contentsline {section}{\numberline {2.8}Additive Nethoden}{24}{section.2.8}
\contentsline {subsection}{\numberline {2.8.1}Verringerung der f\IeC {\"u}r Berechnungen n\IeC {\"o}tige Zeit}{24}{subsection.2.8.1}
\contentsline {paragraph}{\nonumberline Berechnung mit 16 Bit Gleitkomma}{25}{section*.24}
\contentsline {subsection}{\numberline {2.8.2}Beschleunigung der Berechnung des Gradientenabstiegsverfahren}{26}{subsection.2.8.2}
\contentsline {subsubsection}{\nonumberline Accelerating CNN Training by Sparsifying Activation Gradients}{27}{section*.30}
\contentsline {subsubsection}{\nonumberline Weight Normalization: A Simple Reparameterization to Accelerate Training of Deep Neural Networks}{27}{section*.31}
\contentsline {subsubsection}{\nonumberline Accelerating Deep Neural Network Training with Inconsistent Stochastic Gradient Descent}{27}{section*.32}
\contentsline {subsubsection}{\nonumberline Accelerated CNN Training Through Gradient Approximation}{27}{section*.33}
\contentsline {subsection}{\numberline {2.8.3}Verfahren zum Verwenden maximaler Batchgr\IeC {\"o}\IeC {\ss }en}{27}{subsection.2.8.3}
\contentsline {chapter}{\numberline {3}\IeC {\"U}berblick \IeC {\"u}ber die Arbeit}{29}{chapter.3}
\contentsline {section}{\numberline {3.1}Experimentelles Setup}{29}{section.3.1}
\contentsline {subsection}{\numberline {3.1.1}Hardware}{29}{subsection.3.1.1}
\contentsline {subsection}{\numberline {3.1.2}Wahl des Frameworks}{29}{subsection.3.1.2}
\contentsline {subsection}{\numberline {3.1.3}verwendete Netzarchitektur}{30}{subsection.3.1.3}
\contentsline {subsection}{\numberline {3.1.4}Baseline Netz}{31}{subsection.3.1.4}
\contentsline {subsubsection}{\nonumberline Evaluierung des breiteren Baseline-Netzes}{31}{section*.38}
\contentsline {subsubsection}{\nonumberline Evaluierung des schmalleren Baseline-Netzes}{34}{section*.41}
\contentsline {section}{\numberline {3.2}Konzept}{34}{section.3.2}
\contentsline {chapter}{\numberline {4}Untersuchung von MorphNet}{37}{chapter.4}
\contentsline {section}{\numberline {4.1}Evaluierung der einzelnen Schritte von MorphNet}{37}{section.4.1}
\contentsline {section}{\numberline {4.2}Evaluierung der Ergebnisse von MorphNet}{38}{section.4.2}
\contentsline {chapter}{\numberline {5}Evaluation des Beschneidens des Netzes}{39}{chapter.5}
\contentsline {section}{\numberline {5.1}Evaluation bei gleichbleibender Batchgr\IeC {\"o}\IeC {\ss }e}{39}{section.5.1}
\contentsline {subsubsection}{\nonumberline Einfluss von verschiedenen Lasso-Ratio Werten auf das Netz}{39}{section*.45}
\contentsline {subsubsection}{\nonumberline Experimente zum Rekonfigurationsintervall}{40}{section*.47}
\contentsline {subsubsection}{\nonumberline Experimente zur Lernrate}{41}{section*.50}
\contentsline {subsubsection}{\nonumberline Experimente zum Grenzwert}{42}{section*.52}
\contentsline {subsubsection}{\nonumberline Diskussion der Methode}{42}{section*.54}
\contentsline {section}{\numberline {5.2}Experimente zur Anpassung der Batchgr\IeC {\"o}\IeC {\ss }e beim Beschneiden des Netzes}{43}{section.5.2}
\contentsline {subsection}{\numberline {5.2.1}Berchnung der Batchgr\IeC {\"o}\IeC {\ss }e abh\IeC {\"a}ngig vom Speicherverbrauch}{43}{subsection.5.2.1}
\contentsline {subsection}{\numberline {5.2.2}Evaluierung der Anpassung der Batchgr\IeC {\"o}\IeC {\ss }e an die Netzgr\IeC {\"o}\IeC {\ss }e}{44}{subsection.5.2.2}
\contentsline {chapter}{\numberline {6}Evaluierung von Net2Net}{45}{chapter.6}
\contentsline {subsection}{\numberline {6.0.1}Evaluierung des Operators f\IeC {\"u}r ein breiteres Netz}{45}{subsection.6.0.1}
\contentsline {subsection}{\numberline {6.0.2}Evaluierung des Operators f\IeC {\"u}r ein tieferes Netz}{46}{subsection.6.0.2}
\contentsline {subsection}{\numberline {6.0.3}Erkunden des Modellraums}{46}{subsection.6.0.3}
\contentsline {chapter}{\numberline {7}Evaluierung}{47}{chapter.7}
\contentsline {subsection}{\numberline {7.0.1}Exponentiell gleitender Durchschnitt}{48}{subsection.7.0.1}
\contentsline {chapter}{\numberline {8}Vergleich}{49}{chapter.8}
\contentsline {chapter}{\numberline {9}Evaluation}{51}{chapter.9}
\contentsline {chapter}{\numberline {10}Ausblick und Fazit}{53}{chapter.10}
\contentsline {chapter}{\numberline {A}d}{55}{appendix.A}
\contentsline {chapter}{Abbildungsverzeichnis}{58}{chapter*.60}
\contentsline {chapter}{Literaturverzeichnis}{59}{chapter*.60}
