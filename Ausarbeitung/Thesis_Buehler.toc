\babel@toc {german}{}
\contentsline {chapter}{\numberline {1}Einleitung}{1}{chapter.1}
\contentsline {section}{\numberline {1.1}Motivation und Hintergrund dieser Arbeit}{1}{section.1.1}
\contentsline {section}{\numberline {1.2}Aufbau der Arbeit}{1}{section.1.2}
\contentsline {chapter}{\numberline {2}Stand der Wissenschaft}{3}{chapter.2}
\contentsline {section}{\numberline {2.1}Funktionsweise eines CNN}{3}{section.2.1}
\contentsline {subsection}{\numberline {2.1.1}Faltung}{3}{subsection.2.1.1}
\contentsline {section}{\numberline {2.2}Suchbegriffe}{3}{section.2.2}
\contentsline {section}{\numberline {2.3}verwendete Datensets}{3}{section.2.3}
\contentsline {section}{\numberline {2.4}\IeC {\"U}berblick \IeC {\"u}ber die g\IeC {\"a}ngigen Methoden}{4}{section.2.4}
\contentsline {subsection}{\numberline {2.4.1}Verringerung der f\IeC {\"u}r Berechnungen n\IeC {\"o}tige Zeit}{5}{subsection.2.4.1}
\contentsline {paragraph}{\nonumberline Berechnung mit 16 Bit Gleitkomma}{5}{section*.13}
\contentsline {subparagraph}{\nonumberline 32 Bit Mastergewichte und Updates}{6}{section*.16}
\contentsline {subsubsection}{\nonumberline Sklaierung der Loss-Funktion}{6}{section*.19}
\contentsline {subsubsection}{\nonumberline Arithmetische Pr\IeC {\"a}zision}{6}{section*.20}
\contentsline {subsection}{\numberline {2.4.2}Berechnung mit 16 Bit Dynamischen Festkommazahlen}{6}{subsection.2.4.2}
\contentsline {section}{\numberline {2.5}Beschleunigung der Berechnung des Gradientenabstiegsverfahren}{7}{section.2.5}
\contentsline {subsection}{\numberline {2.5.1}Accelerating CNN Training by Sparsifying Activation Gradients}{7}{subsection.2.5.1}
\contentsline {subsection}{\numberline {2.5.2}Weight Normalization: A Simple Reparameterization to Accelerate Training of Deep Neural Networks}{7}{subsection.2.5.2}
\contentsline {subsection}{\numberline {2.5.3}Accelerating Deep Neural Network Training with Inconsistent Stochastic Gradient Descent}{7}{subsection.2.5.3}
\contentsline {subsection}{\numberline {2.5.4}Accelerated CNN Training Through Gradient Approximation}{7}{subsection.2.5.4}
\contentsline {section}{\numberline {2.6}Verfahren um weniger Trainingsdaten zu verwenden}{8}{section.2.6}
\contentsline {subsection}{\numberline {2.6.1}Stochastisches Pooling}{8}{subsection.2.6.1}
\contentsline {subsection}{\numberline {2.6.2}Lernen von Struktur und St\IeC {\"a}rke von CNNs}{8}{subsection.2.6.2}
\contentsline {section}{\numberline {2.7}Strukturelle Ver\IeC {\"a}nderungen zur Beschleunigung des Trainings}{9}{section.2.7}
\contentsline {subsection}{\numberline {2.7.1}Pruning um Trainingszeit zu minimieren}{9}{subsection.2.7.1}
\contentsline {subsubsection}{\nonumberline Prune Train}{9}{section*.21}
\contentsline {subsubsection}{\nonumberline The Lottery Ticket Hypothesis}{11}{section*.22}
\contentsline {subsection}{\numberline {2.7.2}Net 2 Net}{11}{subsection.2.7.2}
\contentsline {subsection}{\numberline {2.7.3}Kernel rescaling}{11}{subsection.2.7.3}
\contentsline {subsection}{\numberline {2.7.4}Resource Aware Layer Replacement}{11}{subsection.2.7.4}
\contentsline {section}{\numberline {2.8}Weitere Herangehensweisen}{12}{section.2.8}
\contentsline {subsection}{\numberline {2.8.1}Tree CNN}{12}{subsection.2.8.1}
\contentsline {subsection}{\numberline {2.8.2}Standardization Loss}{12}{subsection.2.8.2}
\contentsline {subsection}{\numberline {2.8.3}Wavelet}{12}{subsection.2.8.3}
\contentsline {chapter}{\numberline {3}Experimentelle Untersuchung der m\IeC {\"o}glichen Strategien}{13}{chapter.3}
\contentsline {section}{\numberline {3.1}Experimentales Setup}{13}{section.3.1}
\contentsline {section}{\numberline {3.2}\IeC {\"U}berblick \IeC {\"u}ber die m\IeC {\"o}glichen Strategien}{13}{section.3.2}
\contentsline {subsection}{\numberline {3.2.1}Zahlenformate}{13}{subsection.3.2.1}
\contentsline {subsection}{\numberline {3.2.2}Beschleunigung der Berechnung des Gradientenabstiegverfahren}{14}{subsection.3.2.2}
\contentsline {subsection}{\numberline {3.2.3}Verfahren um weniger Trainingsdaten zu verwenden}{14}{subsection.3.2.3}
\contentsline {subsection}{\numberline {3.2.4}Strukturelle Ver\IeC {\"a}nderungen}{14}{subsection.3.2.4}
\contentsline {subsection}{\numberline {3.2.5}andere Herangehensweisen}{14}{subsection.3.2.5}
\contentsline {subsection}{\numberline {3.2.6}Tensorflow vs. PyTorch}{14}{subsection.3.2.6}
\contentsline {section}{\numberline {3.3}Durchf\IeC {\"u}hrung der Experimente}{14}{section.3.3}
\contentsline {subsection}{\numberline {3.3.1}Kombination von Net2Net mit PruneTrain}{14}{subsection.3.3.1}
\contentsline {section}{\numberline {3.4}Evaluation der Ergebenisse}{14}{section.3.4}
\contentsline {chapter}{\numberline {4}Konklusion}{15}{chapter.4}
\contentsline {part}{\numberline {I}Additional information}{17}{part.1}
\contentsline {chapter}{Abbildungsverzeichnis}{19}{chapter*.23}
\contentsline {chapter}{Algorithmenverzeichnis}{21}{chapter*.24}
\contentsline {chapter}{Quellcodeverzeichnis}{23}{chapter*.25}
\contentsline {chapter}{Literaturverzeichnis}{25}{chapter*.25}
