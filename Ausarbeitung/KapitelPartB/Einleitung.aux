\relax 
\providecommand\hyper@newdestlabel[2]{}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Experimentelle Untersuchung der m\IeC {\"o}glichen Strategien}{13}{chapter.3}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{lol}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Experimentales Setup}{13}{section.3.1}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}\IeC {\"U}berblick \IeC {\"u}ber die m\IeC {\"o}glichen Strategien}{13}{section.3.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}Zahlenformate}{13}{subsection.3.2.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}Beschleunigung der Berechnung des Gradientenabstiegverfahren}{14}{subsection.3.2.2}}
\@writefile{toc}{\contentsline {subsubsection}{\nonumberline Accelerating CNN Training by Sparsifying Activation Gradients}{14}{section*.19}}
\@writefile{toc}{\contentsline {subsubsection}{\nonumberline Weight Normalization: A Simple Reparameterization to Accelerate Training of Deep Neural Networks}{14}{section*.20}}
\@writefile{toc}{\contentsline {subsubsection}{\nonumberline Accelerating Deep Neural Network Training with Inconsistent Stochastic Gradient Descent}{14}{section*.21}}
\@writefile{toc}{\contentsline {subsubsection}{\nonumberline Accelerated CNN Training Through Gradient Approximation}{14}{section*.22}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.3}Verfahren um weniger Trainingsdaten zu verwenden}{14}{subsection.3.2.3}}
\@writefile{toc}{\contentsline {subsubsection}{\nonumberline Stochastisches Pooling}{14}{section*.23}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.4}Lernen von Struktur und St\IeC {\"a}rke von CNNs}{14}{subsection.3.2.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.5}Strukturelle Ver\IeC {\"a}nderungen}{14}{subsection.3.2.5}}
\@writefile{toc}{\contentsline {subsubsection}{\nonumberline PruneTrain}{14}{section*.24}}
\@writefile{toc}{\contentsline {subsubsection}{\nonumberline Net2Net}{14}{section*.25}}
\citation{largeBatch}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.6}andere Herangehensweisen}{15}{subsection.3.2.6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.7}Tensorflow vs. PyTorch}{15}{subsection.3.2.7}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Durchf\IeC {\"u}hrung der Experimente}{15}{section.3.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.1}Einfluss der Batch Gr\IeC {\"o}\IeC {\ss }e}{15}{subsection.3.3.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.2}Kombination von Net2Net mit PruneTrain}{15}{subsection.3.3.2}}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Evaluation der Ergebenisse}{15}{section.3.4}}
\@setckpt{KapitelPartB/Einleitung}{
\setcounter{page}{16}
\setcounter{equation}{0}
\setcounter{enumi}{0}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{0}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{3}
\setcounter{section}{4}
\setcounter{subsection}{0}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{0}
\setcounter{table}{0}
\setcounter{float@type}{16}
\setcounter{Item}{0}
\setcounter{Hfootnote}{0}
\setcounter{bookmark@seq@number}{45}
\setcounter{AM@survey}{0}
\setcounter{parentequation}{0}
\setcounter{subfigure}{0}
\setcounter{lofdepth}{1}
\setcounter{subtable}{0}
\setcounter{lotdepth}{1}
\setcounter{@todonotes@numberoftodonotes}{11}
\setcounter{NAT@ctr}{0}
\setcounter{ContinuedFloat}{0}
\setcounter{lstnumber}{1}
\setcounter{algorithm}{0}
\setcounter{ALC@unique}{0}
\setcounter{ALC@line}{0}
\setcounter{ALC@rem}{0}
\setcounter{ALC@depth}{0}
\setcounter{section@level}{1}
\setcounter{lstlisting}{0}
}
