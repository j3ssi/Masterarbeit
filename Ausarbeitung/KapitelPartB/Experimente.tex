\section{Experimentales Setup}


\subsection{Hardware}
Server mit 4 Graka:

2 mal Geforce GTX 1080 Ti mit CUDA Version 10.1 

2 mal Geforce RTX 2080 Ti mit CUDA Version 10.1

\subsection{Wahl des Frameworks}

Es wird mit pytorch gearbeitet, da pytorch gegenüber anderen Frameworks eine grössere Flexibiltät erlaubt. Ausserdem ist eine fast vollständige Implementierung von PruneTrain in Pytorch geschrieben. Diese wird im nächsten Kapitel untersucht und soweit erweitert, dass es dem Stand im PruneTrain Paper entspricht.



\section{Untersuchung von PruneTrain}


\subsection{verwendete Netzarchitektur}\label{sec:archi}
Die PruneTrain Implementierung hat initial mehrere verschiedene Netzarchitekturen zur Auswahl:
\begin{itemize}
 \item AlexNet
 \item ResNet 32/50
 \item vgg 8/11/13/16
 \item mobilenet
\end{itemize}

Schränke diese Auswahl auf ResNet ein.
Gründe hierfür:
\begin{itemize}
 \item Da die Überlegung besteht diese Netze tiefer zu machen wähle ResNet, da die Identity-Übergänge dem Netz erlauben das degradation Problem zu umgehen während das Netz noch tiefer/ breiter wird.
 \item Festlegung auf eine Architektur um Umfang der Arbeit zu begrenzen
\end{itemize}

Erweitere dies jedoch durch beliebige grosse ResNets. Ein ResNet ist hier durch 4 Parameter charaterisiert:

\begin{itemize}
 \item $s$: Anzahl an Stages, die das ResNet hat
 \item $[n]:$ Anzahl von Blöcken pro Stage 
 \item $l$: Anzahl von (Conv+Batch)-Layer pro Block
 \item $b$: Boolean Parameter, der angibt ob die Blöcke im Netz die Bootleneck-Eigenschaft haben
\end{itemize}
\todo[inline]{Bottleneck -Eigenschaft}

\subsection{Nachvollziehbarkeit der PruneTrain Ergebnisse}
\color{blue1}
Evaluation auf Cifar10, Cifar100 und auf ImageNet.


Als Netze werden Resnet32, Resnet 50 aus den Resnets verwendet.


Es werden mehrere GPUs gemeinsam benutzt. Hier nur eine einzelne 2080.


Zunächst wird überprüft wieviel Trainingsflops, Trainingszeit und andere grössen durch PruneTrain ohne Anpassen der Batchgrösse gespart werden können.


Für diese Arbeit interessant ist hier hauptsächlich die gesparte Zeit. Für ResNet32 wird hier angegeben, dass nur 81 \% der Trainingszeit des Baseline Netzes verwendet werden. Bei einem minimalen Accuracy Verlust von 1.8\%. 


Da beim Training mit PruneTrain ganze Blöcke entfernt werden ist diese Zeitersparnis realistisch
\todo[inline]{Genaue Zahlen für Accuracy und Zeitersparnis}


Als nächster Schritt wird dies für Resnet50 und Cifar100 verglichen. Hier wird allerdings nicht der gesamte Speicher der Grafikkarte ausgefüllt sondern nur auf einen gleichmässigen maximalen Speicherverbrauch geachtet im Verlauf der Batch Size Anpassung.







Danach wird für Resnet50 und ImageNet verglichen, wie viel zusätzlich durch das vergrössern der Batch size gewonnen werden kann.
Hier wird der gesamte Speicher der Grafikkarte verwendet.

Das heisst es ist nötig, zu wissen wie gross die Batches maximal sein dürfen um keinen Out of Memory Error zu provozieren. Zusätzlich kann dann berechnet werden, inwieweit die Batchgrösse weiter angehoben werden kann bei kleiner werdendem Netz

Um die Anpassung der Batchgröße an die Verkleinerung des Netzwerkes durch das Prunen zu implmentieren muss zunächst die Batchgröße des Ausgangsnetzes so gewählt werden, dass der GPU-Speicher maximal ausgelastet ist.



Theoretisch sollte hierfür nachdem Übertragen des Modells der freie Speicher ausglesen werden und anhand des Speicherverbrauchs eines Elements des Datensatzes berechnet werden, wie gross die Batchgröße maximal sein darf. Leider führt diese Methode nicht zum gewünschten Ergebnis, da der ausgelesene freie Speicher nicht dem tratsächlich allokierbaren Speicher entspricht.
Der Grund hierfür ist ein Fragmentierungsproblem. Verschiedene freie Blöcke können nicht zu einem grossen allokierbaren Block zusammengefügt werden.\todo[inline]{Quelle}. 

Diese Problem wird mit einer Methode, die für einen beliebigen Datensatz und für eine beliebige Modellgrösse die maximale Batchgröße berechnet, gelöst. Hierfür wird für einige verschiedene Modellgrößen durch eine binäre Suche die maximale Batch Size ermittelt. Gleichzeitig wird für die jeweilige Modellgrösse die Anzahl an Parametern, die das Modell hat gezählt. Diese Größen sind in Tabelle \ref{tab:batchSize} eingetragen.



\todo[inline]{Tabelle mit neuen Zahlen updaten, da mit kaputter Grafikkarte berechnet}
\begin{table}[]
\begin{tabular}{c|c|c|c|c|c|c|c|c|}
\cline{2-9}
                         & \multicolumn{2}{c|}{s=1}  & \multicolumn{2}{c|}{s=2}  & \multicolumn{2}{c|}{s=3}  & \multicolumn{2}{c|}{s=4}  \\ \cline{1-1}
\multicolumn{1}{|l|}{}   & \#Para & Batch & \#Para & Batch & \#Para & Batch & \#Para & Batch \\ \hline
\multicolumn{1}{|l|}{1}  & 7642         & 14272      & 31034        & 5856       & 123898       & 2704       & 493946       & 1344       \\ \hline
\multicolumn{1}{|l|}{2}  & 14650        & 8816       & 65882        & 3328       & 269722       & 1472       & 1082906      & 688        \\ \hline
\multicolumn{1}{|l|}{3}  & 21658        & 6512       & 100730       & 2368       & 415546       & 1024       & 1671866      & 480        \\ \hline
\multicolumn{1}{|l|}{4}  & 28666        & 5072       & 135578       & 1808       & 561370       & 784        & 2260826      & 368        \\ \hline
\multicolumn{1}{|l|}{5}  & 35674        & 4208       & 170426       & 1488       & 707194       & 624        & 2840786      & 288        \\ \hline
\multicolumn{1}{|l|}{6}  & 42682        & 3568       & 205274       & 1232       & 853018       & 528        & 3438746      & 240        \\ \hline
\multicolumn{1}{|l|}{7}  & 49690        & 3120       & 240122       & 1072       & 998842       & 464        & 4027706      & 208        \\ \hline
\multicolumn{1}{|l|}{8}  & 56698        & 2736       & 274970       & 944        & 1144666      & 400        & 4616666      & 176        \\ \hline
\multicolumn{1}{|l|}{9}  & 63706        & 2464       & 309818       & 848        & 1290490      & 352        & 5205626      & 160        \\ \hline
\multicolumn{1}{|l|}{10} & 70714        & 2224       & 344666       & 752        & 1436314      & 320        & 5794586      & 145        \\ \hline
\multicolumn{1}{|l|}{11} & 77722        & 2049       & 379514       & 688        & 1582138      & 288        &              &            \\ \hline
\end{tabular}
\end{table}


Mit Hilfe dieser Grössen wird für jede einzelne Stagegröße eine Gerade gefittet.
In Abbildung \ref{fig:linearBlocks} ist zu sehen, dass Die Parameteranzahl in Zusammenhang mit der Anzahl an Blöcken linear steigt.


\begin{figure}[h]
 \centering
 \includegraphics[width=0.8\textwidth]{KapitelPartB/Images/linearBlocks.png}
 % batchSizevsTime.png: 387x367 px, 96dpi, 10.24x9.71 cm, bb=0 0 290 275
 \caption{Batch Size vs Trainings Time über eine Epoche}
 \label{fig:linearBlocks}
\end{figure}




Die maximal mögliche Batchgrösse in Abbildung \ref{fig:maxBatchSize} sinkt im Gegensatz dazu stärker als linear bei mehr Blöcken im Netz. Dies liegt darin begründet, dass für ein grösseres Netz mehr Werte zwischengespeichert werden müssen, was den Speicherbedarf erhöht.

\begin{figure}[h]
 \centering
 \includegraphics[width=0.8\textwidth]{KapitelPartB/Images/maxBatchSize.png}
 % batchSizevsTime.png: 387x367 px, 96dpi, 10.24x9.71 cm, bb=0 0 290 275
 \caption{Batch Size vs Trainings Time über eine Epoche}
 \label{fig:maxBatchSize}
\end{figure}




Gesucht ist ein idealerweise linearer Zusammenhang zwischen der Parameteranzahl und der Batchgrösse. Um diesen herzustellen wird die Parameteranzahl durch die Batchanzahl geteilt. Das Ergebnis hiervon ist in Abbildung \ref{fig:quotient} zu sehen.

\begin{figure}[h]
 \centering
 \includegraphics[width=0.8\textwidth]{KapitelPartB/Images/quotient.png}
 % batchSizevsTime.png: 387x367 px, 96dpi, 10.24x9.71 cm, bb=0 0 290 275
 \caption{Batch Size vs Trainings Time über eine Epoche}
 \label{fig:quotient}
\end{figure}


Da diese Kurve ähnlich der Batchsize-Kurve aussieht wird die Hypothese untersucht, ob hier ein linearer Zusammenhang besteht. Zu diesem Zweck wird die Batchgrösse durch das Ergebnis geteilt.

Augenscheinlich liegt hier ein linearer Zusammenhang vor. Daher wird hier eine Gerade gefittet.
Es entsteht die Abbildung \ref{fig:gerade}.

\begin{figure}[h]
 \centering
 \includegraphics[width=0.8\textwidth]{KapitelPartB/Images/gerade.png}
 % batchSizevsTime.png: 387x367 px, 96dpi, 10.24x9.71 cm, bb=0 0 290 275
 \caption{Batch Size vs Trainings Time über eine Epoche}
 \label{fig:gerade}
\end{figure}




Die gefittete Gerade hat die Gleichung: $$ f(x)=0.11 \cdot x +  0.15 $$

\todo{Hier muss noch das Fitten des Modells und der t-Test erklärt werden}
Diese gefittete Gerade wird mittels t-Test darauf überprüft wie wahrscheinlich beim Fitten der Gerade ein Fehler 1. Art auftritt.

Hierfür werden folgende Hypothesen aufgestellt:


Da der p-Wert für diese Gerade bei $p=2,911e^{-16}$ und damit weit unter de Signifikanzniveau von $\alpha=0,05$ kann die $H_0$ Hypothese abgelehnt werden und die Alternativhypothese angenommen werden.

Dies bestätigt statistisch eine hohe Wahrscheinlichkeit, dass die gefittete Gerade richtig ist.


In Tabelle \todo{Tabelle} werden die Werte für die anderen Stages zusammengefasst. Zu sehen ist, dass für jeden Stage die gefittete Gerade ähnlich im t-Test abschneidet.




Bei Cifar100 ist zu sehen, dass die gleiche maximale Batchgrösse verwendet werden kann. Bei gleicher Grösse der Bilder (32x32 Pixel) ändert sich hier nur die Anzahl an Parametern in der letzten Schicht.





Als nächsten Schritt wird untersucht wie das Intervall wie häufig rekonfiguriert wird den Zusammenhang zwischen Inferenz Flop und der Validation Accuracy verändert.


Die nächste Untersuchung über das Sparen von Kommunikationskosten beim Verteilten Training macht hier keinen Sinn da nur eine einzelne Graka genutzt wird.


Abschliessend wird noch evaluiert, wie die Dichte der Gewichte mit der Dichte der Kanäle nachdem Training zusammenhängen um eventuell durch spezifische Inferenzhardware weiter zusparen.





\subsection{Einfluss der Batchgröße auf PruneTrain}\label{sec:batch}
Bei grösserer Batchgrösse wird auch das Netz schneller. Dies ist in Abildung \ref{fig:batchVsTime} für das ResNet und die verwendete Hardware abgebildet.

\begin{figure}[h]
 \centering
 \includegraphics[width=0.8\textwidth]{KapitelPartB/Images/batchSizevsTime.png}
 % batchSizevsTime.png: 387x367 px, 96dpi, 10.24x9.71 cm, bb=0 0 290 275
 \caption{Batch Size vs Trainings Time über eine Epoche}
 \label{fig:batchVsTime}
\end{figure}


Wie zu sehen ist, wird die Trainingszeit pro Epoche mit grösserer Batchgrösse kleiner. Die höhere Batchgrösse sorgt neben der geringeren Trainingszeit auch für weniger Gewichtsupdates. Dies führt zu einer geringeren Generalisationsfähigkeit und damit zu einer geringeren Klassifikationsleistung \cite{largeBatch}. Um diesen Verlust an Klassifikationsleistung auszugleichen gibt es die Möglichkeit die Lernrate anzupassen und eine andere Batch Normalisation zu verwenden \cite{largeBatch}. Diese Technik funktioniert laut dem Paper "`Train longer, generalize better: closing the generalization gap in large batch training of neural networks"' bereits auf residualen Netzen wie sie in dieser Arbeit verwendet werden \cite{largeBatch}. Vorallem bleibt die Einsparung bei der Trainingszeit durch diese Technik intakt \cite{largeBatch}.

Ist dieser Effekt auf PruneTrain übertragbar?


Eine grössere Batchsize sorgt auf jeden Fall für signifikant weniger Verkleinerung des Netzes.
\todo{t-Test um statistisch zu zeigen, dass das signifikant ist}

Die Frage die sich hier stellt ist, ob mit Hilfe von largeBatch bei maximaler Batchsize die Verkleinerungsrate steigt  


\subsubsection{Ghost Batch Norm und LR Anpassung}

\subsubsection{Untersuchung}
Im nächsten Schritt wird untersucht, ob diese Vorteile auch für den PruneTrain Vorgang genutzt werden kann. Dafür wird zunächst untersucht, welchen Effekt eine grössere Batchgrösse auf PruneTrain hat.




Es stellt sich die Frage, ob das einen so grossen Einfluss auf die Ausführungszeit hat.



Man sieht, dass mit steigender Batchgröße die Ausführungszeit sinkt. 

Errechne zusätzlich noch ein Modell, wo abhängig von der Modellgrösse währenddem Pruning die Batchgrösse angepasst wird.



\cite{largeBatch} gibt an, dass mit grösserer Batch size die Accuracy weniger wird. Aber dort wird ein Verfahren angegben, welches diesen Effekt entfernen kann.
Da dieser Effekt da sehr deutlich gezeigt wird hier im nächsten Unterkapitel nur die Überprüfung, ob dieser Effekt auf bei geprunten Netzwerken funktioniert.
\subsection{Einfluss der Batchgrösse und der Lernrate auf die Verkleinerung des Netzes}
\todo[inline,color=blue]{Untersuche, ob largeBatch auch auf ein PruneTrain Netzwerk anwendbar ist.}
\todo[inline,color=brown]{Untersuche, ob die Grösse des Batches beeinflusst, wie viel vom Netz geprunt wird}



\color{black}
\section{PruneTrain als MorphNet}

\subsection{Net 2 Net}
\todo[inline]{Zeige wie Net2Net aus einem Netzwerk ein tieferes oder breiteres Netz macht}

\subsection{Morphnet}
MorphNet macht alle Layer breiter um sie dann mit einem speziellen Regularisierer breiter zu machen. Dieser Regularisierer hat verschiedene mögliche Zielgrössen (Modelgrösse, Flops oder Inferenz-Zeit).
Die Frage stellt sich hier, ob das Netz besser wird wenn alle Schichten breiter gemacht werden um später wieder geprunt zuwerden.
\todo[inline,color=blue]{Vollziehe mit PrunTrain + Net2Net nach, ob dies funktioniert wie MorphNet}

Weiterhin besteht die Möglichkeit das Netz nicht nur breiter zu machen sondern auch tiefer.
\todo[inline,color=brown]{Mache das Netz tiefer}
\todo[inline, color =blue]{Suche Kriterien, die entscheiden ob das Netz tiefer sein sollte}


MorphNet erwähnt, dass es Sinn macht nicht im ganzen Netz denn Wider Operator anzuwenden sonder nur da wo der Regularisierer das Netz nicht schmaller macht.
\todo[inline, color=blue]{Entwickle Möglichkeit dies direkter da anzuwenden, wo nicht geprunt wurde}


\section{Überblick über die möglichen Strategien}

Welche Strategien aus Kapitel 2 sind überhaupt durchführbar?
Hier werden nur die Strategien aufgeführt, welche überhaupt auf vernünftig grossen Datensätzen funktionieren und von der Technik und dem Aufwand her möglich sind.
Die Strategien sind aufgeteilt in Unterkapitel. 

Alle möglichen Kombinationen von Strategien sind zuviele. Daher sinnvolle Vorauswahl treffen.  
Bei mehreren gleichartigen/ konkurierenden Ansätze drekter Vergleich und dann den besten auswählen.
\subsection{Zahlenformate}

\begin{itemize}
 \item FP16 bereits probiert
\end{itemize}


FP16 nur auf RTX 2080 sinnvoll
Bietet nach erster Messung etwa 28 \% Prozent Gewinn.

Code für dieses Verfahren liegt vor: Amp apex von Nvidia

AMP bietet 3 mögliche Optimierungsstufen:

O1
Patch all Torch functions and Tensor methods to cast their inputs according to a whitelist-blacklist model. Whitelist ops (for example, Tensor Core-friendly ops like GEMMs and convolutions) are performed in FP16. Blacklist ops that benefit from FP32 precision (for example, softmax) are performed in FP32. O1 also uses dynamic loss scaling, unless overridden.

02
casts the model weights to FP16, patches the models forward method to cast input data to FP16, keeps batchnorms in FP32, maintains FP32 master weights, updates the optimizer’s paramgroups so that the optimizer.step() acts directly on the FP32 weights (followed by FP32 master weight-FP16 model weight copies if necessary), and implements dynamic loss scaling (unless overridden). Unlike O1, O2 does not patch Torch functions or Tensor methods.


O3
may not achieve the stability of the true mixed precision options O1 and O2. However, it can be useful to establish a speed baseline for your model, against which the performance of O1 and O2 can be compared. If your model uses batch normalization, to establish speed of light you can try O3 with the additional property override keepBatchnormfp32=True (which enables cudnn batchnorm, as stated earlier).

Hier nur O0, O1 und O2 dargestellt, da O3 absolut nicht mithalten kann was Performance angeht.

\begin{figure}[h]
 \centering
 \includegraphics[width=0.8\textwidth]{KapitelPartB/Images/timeVsBatchSize_Amp.png}
 % timeVsBatchSize_Amp.png: 387x367 px, 96dpi, 10.24x9.71 cm, bb=0 0 290 275
 \caption{Vergleich Trainingszeit einer Epoche für verschiedene Optimierungsstufen von Amp Apex. DunkelBlau=O0; Schwarz = O1; Hellblau=O2}
 \label{fig:amp}
\end{figure}

\todo[inline,color=brown]{Weitere Versuche, die zeigen ob die Zeiten grossen statistischen Schwankungen unterliegen.}
\url{https://developer.download.nvidia.com/video/gputechconf/gtc/2019/presentation/s9998-automatic-mixed-precision-in-pytorch.pdf} zeigt, dass bezüglich der Accuracy kein Verlust zu erwarten ist.

Da O2 gegenüber O1 keinen signifikanten zusätzlichen Gewinn bringt nutze O1.
\subsection{Beschleunigung der Berechnung des Gradientenabstiegverfahren}


Accelerating CNN Training by Sparsifying Activation Gradients funktioniert nur auf Toy-Benchmarks 


\subsubsection{Weight Normalization: A Simple Reparameterization
to Accelerate Training of Deep Neural Networks}

\todo[inline,color=blue]{Testen ob es funktioniert}
Könnte funktionieren. Code für Lasagne: https://github.com/TimSalimans/weight\_norm


\subsubsection{Accelerating Deep Neural Network Training with Inconsistent Stochastic Gradient Descent}

Interessant bisher kein Code verfügbar
\todo[inline, color=blue]{Implementieren (ist einfach) und testen}

\subsubsection{Accelerated CNN Training Through Gradient Approximation }

Interessant bisher kein Code verfügbar


\subsubsection{Sind diese Verfahren theoretisch kombinierbar}
\todo[inline,color=blue]{Testen, wenn die anderen funktionieren}
\subsection{Verfahren um weniger Trainingsdaten zu verwenden}


\subsubsection{Stochastisches Pooling}

Klingt sehr interessant und könnte für deutlich kleinere Trainingsdatenmenge sorgen
Oder alternativ bei gleicher Trainingsdatenmenge die Accuracy verbessern
https://github.com/Shuangfei/s3pool
\todo[inline,color=blue]{Testen}

\subsection{Lernen von Struktur und Stärke von CNNs}

bisher kein Code verfügbar.Klingt aber interessant
\todo[inline]{Ist zwar interessant aber ohne Code dazu wohl zu aufwändig}




\section{Schnelleres MorphPruneTrain}
FP16 + plus ein Verfahren aus dem Bereich Gradienten

\todo[inline, color=blue]{Funktioniert erst, wenn die anderen Experimente durchgelaufen sind}
