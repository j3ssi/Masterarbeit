\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand*\new@tpo@label[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\catcode `"\active 
\babel@aux{german}{}
\newlabel{Notation}{{}{\@alpha \c@page }{Mathematical Notation}{chapter*.3}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Einleitung}{1}{chapter.1}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{lol}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{sec:EinleitungGesamt}{{1}{1}{Einleitung}{chapter.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Motivation und Hintergrund dieser Arbeit}{1}{section.1.1}}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{orange}{\leavevmode {\color  {orange}o}}\ Einleitung fertigschreiben -- zum Schluss}{1}{section*.4}}
\pgfsyspdfmark {pgfid1}{20495094}{32595431}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Aufbau der Arbeit}{1}{section.1.2}}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{orange}{\leavevmode {\color  {orange}o}}\ Aufbau der Arbeit -- erst bei fortgeschrittener Arbeit schreiben}{1}{section*.5}}
\pgfsyspdfmark {pgfid2}{20495094}{27498490}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Suchbegriffe}{1}{section.1.3}}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{orange}{\leavevmode {\color  {orange}o}}\ verwendete Suchbegriffe}{1}{section*.6}}
\pgfsyspdfmark {pgfid3}{20495094}{22181858}
\citation{CNNBook}
\citation{neural}
\citation{CNNBook}
\citation{CNNBook}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Stand der Wissenschaft}{3}{chapter.2}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{lol}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Funktionsweise eines CNNs}{3}{section.2.1}}
\newlabel{sec:conv}{{2.1}{3}{Funktionsweise eines CNNs}{section.2.1}{}}
\citation{neural}
\citation{CNNImg}
\citation{CNNImg}
\@writefile{lof}{\contentsline {figure}{\numberline {\relax 2.1}{\ignorespaces Abbildung zur Faltung \cite  {CNNBook}\relax }}{4}{figure.caption.7}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:faltung}{{\relax 2.1}{4}{Abbildung zur Faltung \cite {CNNBook}\relax }{figure.caption.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {\relax 2.2}{\ignorespaces Convolutional Neural Net \cite  {CNNImg}\relax }}{5}{figure.caption.8}}
\newlabel{fig:cnn}{{\relax 2.2}{5}{Convolutional Neural Net \cite {CNNImg}\relax }{figure.caption.8}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}ResNet -- eine neuere CNN-Architektur}{5}{section.2.2}}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Strukturelle Methoden}{5}{section.2.3}}
\citation{ieee}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}MorphNet}{6}{subsection.2.3.1}}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Zeitsparende Nethoden}{6}{section.2.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.1}Verringerung der f\IeC {\"u}r Berechnungen n\IeC {\"o}tige Zeit}{6}{subsection.2.4.1}}
\newlabel{sec:fp16}{{2.4.1}{6}{Verringerung der für Berechnungen nötige Zeit}{subsection.2.4.1}{}}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{orange}{\leavevmode {\color  {orange}o}}\ cite}{6}{section*.9}}
\pgfsyspdfmark {pgfid4}{17933708}{31385549}
\pgfsyspdfmark {pgfid5}{1356433}{31402655}
\pgfsyspdfmark {pgfid6}{3787441}{31131929}
\@writefile{toc}{\contentsline {paragraph}{\nonumberline Berechnung mit 16 Bit Gleitkomma}{6}{section*.10}}
\@writefile{lot}{\contentsline {table}{\numberline {\relax 2.1}{\ignorespaces Darstellbare Zahlen von 16 und 32 Bit\relax }}{6}{table.caption.11}}
\newlabel{tab:numbers}{{\relax 2.1}{6}{Darstellbare Zahlen von 16 und 32 Bit\relax }{table.caption.11}{}}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{orange}{\leavevmode {\color  {orange}o}}\ subnormale Zahlen}{6}{section*.12}}
\pgfsyspdfmark {pgfid9}{18630414}{7288818}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{orange}{\leavevmode {\color  {orange}o}}\ ref}{7}{section*.13}}
\pgfsyspdfmark {pgfid10}{31643128}{22371321}
\pgfsyspdfmark {pgfid13}{37769074}{22388427}
\pgfsyspdfmark {pgfid14}{40200082}{22117701}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{orange}{\leavevmode {\color  {orange}o}}\ ref}{7}{section*.14}}
\pgfsyspdfmark {pgfid15}{23501232}{16043676}
\pgfsyspdfmark {pgfid18}{37769074}{16060782}
\pgfsyspdfmark {pgfid19}{40200082}{15790056}
\@writefile{tdo}{\contentsline {todo}{Figure: Schema}{7}{section*.14}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.2}Beschleunigung der Berechnung des Gradientenabstiegsverfahren}{8}{subsection.2.4.2}}
\@writefile{toc}{\contentsline {subsubsection}{\nonumberline Accelerating CNN Training by Sparsifying Activation Gradients}{8}{section*.15}}
\@writefile{toc}{\contentsline {subsubsection}{\nonumberline Weight Normalization: A Simple Reparameterization to Accelerate Training of Deep Neural Networks}{8}{section*.16}}
\@writefile{toc}{\contentsline {subsubsection}{\nonumberline Accelerating Deep Neural Network Training with Inconsistent Stochastic Gradient Descent}{8}{section*.17}}
\@writefile{toc}{\contentsline {subsubsection}{\nonumberline Accelerated CNN Training Through Gradient Approximation}{8}{section*.18}}
\@writefile{toc}{\contentsline {section}{\numberline {2.5}Verfahren um weniger Trainingsdaten zu verwenden}{8}{section.2.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.1}Stochastisches Pooling}{8}{subsection.2.5.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.2}Lernen von Struktur und St\IeC {\"a}rke von CNNs}{8}{subsection.2.5.2}}
\@writefile{toc}{\contentsline {section}{\numberline {2.6}Strukturelle Ver\IeC {\"a}nderungen zur Beschleunigung des Trainings}{8}{section.2.6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6.1}Pruning um Trainingszeit zu minimieren}{8}{subsection.2.6.1}}
\@writefile{toc}{\contentsline {subsubsection}{\nonumberline Prune Train}{9}{section*.19}}
\@writefile{toc}{\contentsline {subsubsection}{\nonumberline The Lottery Ticket Hypothesis}{11}{section*.20}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6.2}Net 2 Net}{11}{subsection.2.6.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6.3}Kernel rescaling}{11}{subsection.2.6.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6.4}Resource Aware Layer Replacement}{11}{subsection.2.6.4}}
\@writefile{toc}{\contentsline {section}{\numberline {2.7}Weitere Herangehensweisen}{11}{section.2.7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.7.1}Tree CNN}{11}{subsection.2.7.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.7.2}Standardization Loss}{11}{subsection.2.7.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.7.3}Wavelet}{11}{subsection.2.7.3}}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Experimente -- Arbeitstitel}{13}{chapter.3}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{lol}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Experimentales Setup}{13}{section.3.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.1}Hardware}{13}{subsection.3.1.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.2}Wahl des Frameworks}{13}{subsection.3.1.2}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Untersuchung von PruneTrain}{13}{section.3.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}verwendete Netzarchitektur}{13}{subsection.3.2.1}}
\newlabel{sec:archi}{{3.2.1}{13}{verwendete Netzarchitektur}{subsection.3.2.1}{}}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{orange}{\leavevmode {\color  {orange}o}}\ Bottleneck -Eigenschaft}{14}{section*.21}}
\pgfsyspdfmark {pgfid21}{18630414}{23796469}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}Implementierung der Anpassung der Batch Gr\IeC {\"o}\IeC {\ss }e}{14}{subsection.3.2.2}}
\newlabel{sec:batch}{{3.2.2}{14}{Implementierung der Anpassung der Batch Größe}{subsection.3.2.2}{}}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{orange}{\leavevmode {\color  {orange}o}}\ Quelle}{14}{section*.22}}
\pgfsyspdfmark {pgfid22}{18630414}{7365097}
\citation{largeBatch}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{orange}{\leavevmode {\color  {orange}o}}\ Wie gut fittet die Geraden die gegebenen Punkte}{15}{section*.24}}
\pgfsyspdfmark {pgfid23}{20495094}{25255160}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{brown}{\leavevmode {\color  {brown}o}}\ \IeC {\"U}berpr\IeC {\"u}fe, ob dies auch bei einem anderen Datensatz funktioniert. Es sollte funktionieren, wenn die Gr\IeC {\"o}sse eines anderen Datensatzes ins Verh\IeC {\"a}ltnis zu der Gr\IeC {\"o}sse in Cifar10 gesetzt wird}{15}{section*.25}}
\pgfsyspdfmark {pgfid24}{20495094}{22498344}
\@writefile{lof}{\contentsline {figure}{\numberline {\relax 3.1}{\ignorespaces Batch Size vs Trainings Time \IeC {\"u}ber eine Epoche\relax }}{16}{figure.caption.26}}
\newlabel{fig:batchVsTime}{{\relax 3.1}{16}{Batch Size vs Trainings Time über eine Epoche\relax }{figure.caption.26}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.3}Einfluss der Batchgr\IeC {\"o}sse und der Lernrate auf die Verkleinerung des Netzes}{16}{subsection.3.2.3}}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{blue}{\leavevmode {\color  {blue}o}}\ Untersuche, ob largeBatch auch auf ein PruneTrain Netzwerk anwendbar ist.}{16}{section*.27}}
\pgfsyspdfmark {pgfid25}{18630414}{22084258}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{brown}{\leavevmode {\color  {brown}o}}\ Untersuche, ob die Gr\IeC {\"o}sse des Batches beeinflusst, wie viel vom Netz geprunt wird}{16}{section*.28}}
\pgfsyspdfmark {pgfid26}{18630414}{20189121}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.4}Nachvollziehbarkeit der PruneTrain Ergebnisse}{16}{subsection.3.2.4}}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{orange}{\leavevmode {\color  {orange}o}}\ Nachvollziehen der PruneTrain Ergebnisse mit dieser Implementierung}{16}{section*.29}}
\pgfsyspdfmark {pgfid27}{18630414}{14712756}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{orange}{\leavevmode {\color  {orange}o}}\ Vergleiche Hardware}{17}{section*.30}}
\pgfsyspdfmark {pgfid28}{20495094}{32739726}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}PruneTrain als MorphNet}{17}{section.3.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.1}Net 2 Net}{17}{subsection.3.3.1}}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{orange}{\leavevmode {\color  {orange}o}}\ Zeige wie Net2Net aus einem Netzwerk ein tieferes oder breiteres Netz macht}{17}{section*.31}}
\pgfsyspdfmark {pgfid29}{20495094}{25368481}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.2}Morphnet}{17}{subsection.3.3.2}}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{blue}{\leavevmode {\color  {blue}o}}\ Vollziehe mit PrunTrain + Net2Net nach, ob dies funktioniert wie MorphNet}{17}{section*.32}}
\pgfsyspdfmark {pgfid30}{20495094}{14752109}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{brown}{\leavevmode {\color  {brown}o}}\ Mache das Netz tiefer}{17}{section*.33}}
\pgfsyspdfmark {pgfid31}{20495094}{11055090}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{blue}{\leavevmode {\color  {blue}o}}\ Suche Kriterien, die entscheiden ob das Netz tiefer sein sollte}{17}{section*.34}}
\pgfsyspdfmark {pgfid32}{20495094}{9769387}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{blue}{\leavevmode {\color  {blue}o}}\ Entwickle M\IeC {\"o}glichkeit dies direkter da anzuwenden, wo nicht geprunt wurde}{17}{section*.35}}
\pgfsyspdfmark {pgfid33}{18630414}{49357833}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}\IeC {\"U}berblick \IeC {\"u}ber die m\IeC {\"o}glichen Strategien}{18}{section.3.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.1}Zahlenformate}{18}{subsection.3.4.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {\relax 3.2}{\ignorespaces Vergleich Trainingszeit einer Epoche f\IeC {\"u}r verschiedene Optimierungsstufen von Amp Apex. DunkelBlau=O0; Schwarz = O1; Hellblau=O2\relax }}{19}{figure.caption.36}}
\newlabel{fig:amp}{{\relax 3.2}{19}{Vergleich Trainingszeit einer Epoche für verschiedene Optimierungsstufen von Amp Apex. DunkelBlau=O0; Schwarz = O1; Hellblau=O2\relax }{figure.caption.36}{}}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{brown}{\leavevmode {\color  {brown}o}}\ Weitere Versuche, die zeigen ob die Zeiten grossen statistischen Schwankungen unterliegen.}{19}{section*.37}}
\pgfsyspdfmark {pgfid34}{20495094}{20445781}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.2}Beschleunigung der Berechnung des Gradientenabstiegverfahren}{19}{subsection.3.4.2}}
\@writefile{toc}{\contentsline {subsubsection}{\nonumberline Weight Normalization: A Simple Reparameterization to Accelerate Training of Deep Neural Networks}{20}{section*.38}}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{blue}{\leavevmode {\color  {blue}o}}\ Testen ob es funktioniert}{20}{section*.39}}
\pgfsyspdfmark {pgfid35}{18630414}{46734501}
\@writefile{toc}{\contentsline {subsubsection}{\nonumberline Accelerating Deep Neural Network Training with Inconsistent Stochastic Gradient Descent}{20}{section*.40}}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{blue}{\leavevmode {\color  {blue}o}}\ Implementieren (ist einfach) und testen}{20}{section*.41}}
\pgfsyspdfmark {pgfid36}{18630414}{38924755}
\@writefile{toc}{\contentsline {subsubsection}{\nonumberline Accelerated CNN Training Through Gradient Approximation}{20}{section*.42}}
\@writefile{toc}{\contentsline {subsubsection}{\nonumberline Sind diese Verfahren theoretisch kombinierbar}{20}{section*.43}}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{blue}{\leavevmode {\color  {blue}o}}\ Testen, wenn die anderen funktionieren}{20}{section*.44}}
\pgfsyspdfmark {pgfid37}{18630414}{30772869}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.3}Verfahren um weniger Trainingsdaten zu verwenden}{20}{subsection.3.4.3}}
\@writefile{toc}{\contentsline {subsubsection}{\nonumberline Stochastisches Pooling}{20}{section*.45}}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{blue}{\leavevmode {\color  {blue}o}}\ Testen}{20}{section*.46}}
\pgfsyspdfmark {pgfid38}{18630414}{20979748}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.4}Lernen von Struktur und St\IeC {\"a}rke von CNNs}{20}{subsection.3.4.4}}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{orange}{\leavevmode {\color  {orange}o}}\ Ist zwar interessant aber ohne Code dazu wohl zu aufw\IeC {\"a}ndig}{20}{section*.47}}
\pgfsyspdfmark {pgfid39}{18630414}{15301436}
\@writefile{toc}{\contentsline {section}{\numberline {3.5}Schnelleres MorphPruneTrain}{20}{section.3.5}}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{blue}{\leavevmode {\color  {blue}o}}\ Funktioniert erst, wenn die anderen Experimente durchgelaufen sind}{20}{section*.48}}
\pgfsyspdfmark {pgfid40}{18630414}{8864096}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Evaluation}{21}{chapter.4}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{lol}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {part}{\numberline {I}Additional information}{23}{part.1}}
\citation{CNNBook}
\citation{CNNImg}
\@writefile{toc}{\contentsline {chapter}{Abbildungsverzeichnis}{25}{chapter*.49}}
\@writefile{toc}{\contentsline {chapter}{Algorithmenverzeichnis}{27}{chapter*.50}}
\@writefile{toc}{\contentsline {chapter}{Quellcodeverzeichnis}{29}{chapter*.51}}
\bibstyle{alpha}
\bibdata{Literature}
\bibcite{CNNImg}{{CCGS16}{}{{}}{{}}}
\bibcite{CNNBook}{{GBC16}{}{{}}{{}}}
\bibcite{neural}{{Hay98}{}{{}}{{}}}
\bibcite{largeBatch}{{HHS17}{}{{}}{{}}}
\providecommand\NAT@force@numbers{}\NAT@force@numbers
\@writefile{toc}{\contentsline {chapter}{Literaturverzeichnis}{31}{chapter*.51}}
\global\csname @altsecnumformattrue\endcsname
\global\@namedef{scr@dte@part@lastmaxnumwidth}{11.08778pt}
\global\@namedef{scr@dte@chapter@lastmaxnumwidth}{11.8799pt}
\global\@namedef{scr@dte@section@lastmaxnumwidth}{19.68687pt}
\global\@namedef{scr@dte@subsection@lastmaxnumwidth}{28.80675pt}
