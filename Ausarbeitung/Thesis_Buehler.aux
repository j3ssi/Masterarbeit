\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand*\new@tpo@label[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\catcode `"\active 
\babel@aux{german}{}
\newlabel{Notation}{{}{\@alpha \c@page }{Mathematical Notation}{chapter*.3}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Einleitung}{1}{chapter.1}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{lol}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{sec:EinleitungGesamt}{{1}{1}{Einleitung}{chapter.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Motivation und Hintergrund dieser Arbeit}{1}{section.1.1}}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{orange}{\leavevmode {\color  {orange}o}}\ Einleitung fertigschreiben -- zum Schluss}{1}{section*.4}}
\pgfsyspdfmark {pgfid1}{20495094}{26030550}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Aufbau der Arbeit}{1}{section.1.2}}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{orange}{\leavevmode {\color  {orange}o}}\ Aufbau der Arbeit -- erst bei fortgeschrittener Arbeit schreiben}{1}{section*.5}}
\pgfsyspdfmark {pgfid2}{20495094}{20933609}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Suchbegriffe}{1}{section.1.3}}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{orange}{\leavevmode {\color  {orange}o}}\ verwendete Suchbegriffe}{1}{section*.6}}
\pgfsyspdfmark {pgfid3}{20495094}{15616977}
\citation{CNNBook}
\citation{neural}
\citation{CNNBook}
\citation{CNNBook}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Stand der Wissenschaft}{3}{chapter.2}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{lol}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Funktionsweise eines CNNs}{3}{section.2.1}}
\newlabel{sec:conv}{{2.1}{3}{Funktionsweise eines CNNs}{section.2.1}{}}
\citation{CNNImg}
\citation{CNNImg}
\@writefile{lof}{\contentsline {figure}{\numberline {\relax 2.1}{\ignorespaces Abbildung zur Faltung \cite  {CNNBook}\relax }}{4}{figure.caption.7}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:faltung}{{\relax 2.1}{4}{Abbildung zur Faltung \cite {CNNBook}\relax }{figure.caption.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {\relax 2.2}{\ignorespaces Convolutional Neural Net \cite  {CNNImg}\relax }}{4}{figure.caption.8}}
\newlabel{fig:cnn}{{\relax 2.2}{4}{Convolutional Neural Net \cite {CNNImg}\relax }{figure.caption.8}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}\IeC {\"U}berblick \IeC {\"u}ber die g\IeC {\"a}ngigen Methoden}{5}{section.2.2}}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{orange}{\leavevmode {\color  {orange}o}}\ kurzer Sectioneinleitungstext \IeC {\"u}ber die g\IeC {\"a}ngigen Methoden}{5}{section*.9}}
\pgfsyspdfmark {pgfid4}{20495094}{14846944}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Verringerung der f\IeC {\"u}r Berechnungen n\IeC {\"o}tige Zeit}{5}{subsection.2.2.1}}
\citation{ieee}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{orange}{\leavevmode {\color  {orange}o}}\ cite}{6}{section*.10}}
\pgfsyspdfmark {pgfid5}{17933708}{42740258}
\pgfsyspdfmark {pgfid6}{1356433}{42757364}
\pgfsyspdfmark {pgfid7}{3787441}{42486638}
\@writefile{toc}{\contentsline {paragraph}{\nonumberline Berechnung mit 16 Bit Gleitkomma}{6}{section*.11}}
\@writefile{lot}{\contentsline {table}{\numberline {\relax 2.1}{\ignorespaces Darstellbare Zahlen von 16 und 32 Bit\relax }}{6}{table.caption.12}}
\newlabel{tab:numbers}{{\relax 2.1}{6}{Darstellbare Zahlen von 16 und 32 Bit\relax }{table.caption.12}{}}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{orange}{\leavevmode {\color  {orange}o}}\ subnormale Zahlen}{6}{section*.13}}
\pgfsyspdfmark {pgfid10}{18630414}{18759025}
\citation{FPGpu}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{orange}{\leavevmode {\color  {orange}o}}\ ref}{7}{section*.14}}
\pgfsyspdfmark {pgfid11}{31643128}{38768379}
\pgfsyspdfmark {pgfid14}{37769074}{38785485}
\pgfsyspdfmark {pgfid15}{40200082}{38514759}
\@writefile{tdo}{\contentsline {todo}{\color@fb@x {}{black}{}{orange}{\leavevmode {\color  {orange}o}}\ ref}{7}{section*.15}}
\pgfsyspdfmark {pgfid16}{23501232}{32829179}
\pgfsyspdfmark {pgfid19}{37769074}{32846285}
\pgfsyspdfmark {pgfid20}{40200082}{32575559}
\@writefile{tdo}{\contentsline {todo}{Figure: Schema}{7}{section*.15}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}Berechnung mit 16 Bit Dynamischen Festkommazahlen}{7}{subsection.2.2.2}}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Beschleunigung der Berechnung des Gradientenabstiegsverfahren}{7}{section.2.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}Accelerating CNN Training by Sparsifying Activation Gradients}{8}{subsection.2.3.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2}Weight Normalization: A Simple Reparameterization to Accelerate Training of Deep Neural Networks}{8}{subsection.2.3.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.3}Accelerating Deep Neural Network Training with Inconsistent Stochastic Gradient Descent}{8}{subsection.2.3.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.4}Accelerated CNN Training Through Gradient Approximation}{8}{subsection.2.3.4}}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Verfahren um weniger Trainingsdaten zu verwenden}{8}{section.2.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.1}Stochastisches Pooling}{8}{subsection.2.4.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.2}Lernen von Struktur und St\IeC {\"a}rke von CNNs}{8}{subsection.2.4.2}}
\@writefile{toc}{\contentsline {section}{\numberline {2.5}Strukturelle Ver\IeC {\"a}nderungen zur Beschleunigung des Trainings}{8}{section.2.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.1}Pruning um Trainingszeit zu minimieren}{8}{subsection.2.5.1}}
\@writefile{toc}{\contentsline {subsubsection}{\nonumberline Prune Train}{9}{section*.16}}
\@writefile{toc}{\contentsline {subsubsection}{\nonumberline The Lottery Ticket Hypothesis}{11}{section*.17}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.2}Net 2 Net}{11}{subsection.2.5.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.3}Kernel rescaling}{11}{subsection.2.5.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.4}Resource Aware Layer Replacement}{11}{subsection.2.5.4}}
\@writefile{toc}{\contentsline {section}{\numberline {2.6}Weitere Herangehensweisen}{11}{section.2.6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6.1}Tree CNN}{11}{subsection.2.6.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6.2}Standardization Loss}{11}{subsection.2.6.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6.3}Wavelet}{11}{subsection.2.6.3}}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Experimentelle Untersuchung der m\IeC {\"o}glichen Strategien}{13}{chapter.3}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{lol}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Experimentales Setup}{13}{section.3.1}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}\IeC {\"U}berblick \IeC {\"u}ber die m\IeC {\"o}glichen Strategien}{13}{section.3.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}Zahlenformate}{13}{subsection.3.2.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}Beschleunigung der Berechnung des Gradientenabstiegverfahren}{14}{subsection.3.2.2}}
\@writefile{toc}{\contentsline {subsubsection}{\nonumberline Accelerating CNN Training by Sparsifying Activation Gradients}{14}{section*.18}}
\@writefile{toc}{\contentsline {subsubsection}{\nonumberline Weight Normalization: A Simple Reparameterization to Accelerate Training of Deep Neural Networks}{14}{section*.19}}
\@writefile{toc}{\contentsline {subsubsection}{\nonumberline Accelerating Deep Neural Network Training with Inconsistent Stochastic Gradient Descent}{14}{section*.20}}
\@writefile{toc}{\contentsline {subsubsection}{\nonumberline Accelerated CNN Training Through Gradient Approximation}{14}{section*.21}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.3}Verfahren um weniger Trainingsdaten zu verwenden}{14}{subsection.3.2.3}}
\@writefile{toc}{\contentsline {subsubsection}{\nonumberline Stochastisches Pooling}{14}{section*.22}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.4}Lernen von Struktur und St\IeC {\"a}rke von CNNs}{14}{subsection.3.2.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.5}Strukturelle Ver\IeC {\"a}nderungen}{14}{subsection.3.2.5}}
\@writefile{toc}{\contentsline {subsubsection}{\nonumberline PruneTrain}{14}{section*.23}}
\@writefile{toc}{\contentsline {subsubsection}{\nonumberline Net2Net}{14}{section*.24}}
\citation{largeBatch}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.6}andere Herangehensweisen}{15}{subsection.3.2.6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.7}Tensorflow vs. PyTorch}{15}{subsection.3.2.7}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Durchf\IeC {\"u}hrung der Experimente}{15}{section.3.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.1}Einfluss der Batch Gr\IeC {\"o}\IeC {\ss }e}{15}{subsection.3.3.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.2}Kombination von Net2Net mit PruneTrain}{15}{subsection.3.3.2}}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Evaluation der Ergebenisse}{15}{section.3.4}}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Konklusion}{17}{chapter.4}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{lol}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {part}{\numberline {I}Additional information}{19}{part.1}}
\citation{CNNBook}
\citation{CNNImg}
\@writefile{toc}{\contentsline {chapter}{Abbildungsverzeichnis}{21}{chapter*.25}}
\@writefile{toc}{\contentsline {chapter}{Algorithmenverzeichnis}{23}{chapter*.26}}
\@writefile{toc}{\contentsline {chapter}{Quellcodeverzeichnis}{25}{chapter*.27}}
\bibstyle{alpha}
\bibdata{Literature}
\bibcite{CNNImg}{{CCGS16}{}{{}}{{}}}
\bibcite{FPGpu}{{DMM{$^{+}$}18}{}{{}}{{}}}
\bibcite{CNNBook}{{GBC16}{}{{}}{{}}}
\bibcite{neural}{{Hay98}{}{{}}{{}}}
\bibcite{largeBatch}{{HHS17}{}{{}}{{}}}
\providecommand\NAT@force@numbers{}\NAT@force@numbers
\@writefile{toc}{\contentsline {chapter}{Literaturverzeichnis}{27}{chapter*.27}}
\global\csname @altsecnumformattrue\endcsname
\global\@namedef{scr@dte@part@lastmaxnumwidth}{11.08778pt}
\global\@namedef{scr@dte@chapter@lastmaxnumwidth}{11.8799pt}
\global\@namedef{scr@dte@section@lastmaxnumwidth}{19.68687pt}
\global\@namedef{scr@dte@subsection@lastmaxnumwidth}{28.80675pt}
