\chapter{Beschleunigung der Berechnung des Gradientenabstiegsverfahren}
Bei der Beschleunigung der Berechnung des Gradientenabstiegsverfahren gibt es vier verschiedene publizierte Herangehensweisen:
\begin{itemize}
 \item Accelerating CNN Training by Sparsifying Activation Gradients
 \item Weight Normalization: A Simple Reparameterization
to Accelerate Training of Deep Neural Networks
 \item Accelerating Deep Neural Network Training with Inconsistent Stochastic Gradient Descent
 \item Accelerated CNN Training Through Gradient Approximation 
\end{itemize}


\section{Accelerating CNN Training by Sparsifying Activation Gradients}

Funktioniert nur auf Toy-Benchmarks


\section{Weight Normalization: A Simple Reparameterization
to Accelerate Training of Deep Neural Networks}



\section{Accelerating Deep Neural Network Training with Inconsistent Stochastic Gradient Descent}


\section{Accelerated CNN Training Through Gradient Approximation }
