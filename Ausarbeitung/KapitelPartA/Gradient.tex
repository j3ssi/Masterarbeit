\section{Beschleunigung der Berechnung des Gradientenabstiegsverfahren}
Bei der Beschleunigung der Berechnung des Gradientenabstiegsverfahren gibt es vier verschiedene publizierte Herangehensweisen:
\begin{itemize}
 \item Accelerating CNN Training by Sparsifying Activation Gradients
 \item Weight Normalization: A Simple Reparameterization
to Accelerate Training of Deep Neural Networks
 \item Accelerating Deep Neural Network Training with Inconsistent Stochastic Gradient Descent
 \item Accelerated CNN Training Through Gradient Approximation 
\end{itemize}


\subsection{Accelerating CNN Training by Sparsifying Activation Gradients}

Funktioniert nur auf Toy-Benchmarks


\subsection{Weight Normalization: A Simple Reparameterization
to Accelerate Training of Deep Neural Networks}





\subsection{Accelerating Deep Neural Network Training with Inconsistent Stochastic Gradient Descent}




\subsection{Accelerated CNN Training Through Gradient Approximation }
